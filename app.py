# app.py - ä¿®å¤ç‰ˆåªæ£€ç´¢æ¨¡å¼
import streamlit as st
import os
import logging
from src.vector_store import SmartVectorStore
import requests
import json
from typing import List, Dict, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å†°å§é—®ç­”å°è¯¾å ‚",
    page_icon="ğŸ“",
    layout="wide"
)

class DeepSeekAPI:
    """DeepSeek API ç®¡ç†ç±» - è…¾è®¯äº‘OpenAI SDKç‰ˆæœ¬"""
    
    def __init__(self):
        self.base_url = "https://api.lkeap.cloud.tencent.com/v1/chat/completions"
        self.model_name = "deepseek-v3.1"
        
        # åˆå§‹åŒ–session state
        if 'api_key' not in st.session_state:
            st.session_state.api_key = ""
        if 'api_key_set' not in st.session_state:
            st.session_state.api_key_set = False
    
    @property
    def api_key(self):
        return st.session_state.api_key
    
    def set_api_key(self, api_key: str):
        """è®¾ç½®APIå¯†é’¥"""
        if api_key and api_key.strip():
            st.session_state.api_key = api_key.strip()
            st.session_state.api_key_set = True
            st.session_state.api_key_preview = api_key[:8] + "..." + api_key[-4:] if len(api_key) > 12 else api_key
            return True
        else:
            st.error("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„APIå¯†é’¥")
            return False
    
    def is_logged_in(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²ç™»å½•"""
        return bool(st.session_state.api_key and st.session_state.api_key_set)
    
    def test_api_connection(self) -> Dict:
        """æµ‹è¯•APIè¿æ¥"""
        if not self.is_logged_in():
            return {"success": False, "message": "æœªè®¾ç½®APIå¯†é’¥"}
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        test_data = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "user", 
                    "content": "è¯·ç®€å•å›å¤'è¿æ¥æˆåŠŸ'"
                }
            ],
            "max_tokens": 10,
            "temperature": 0.1
        }
        
        try:
            response = requests.post(self.base_url, headers=headers, json=test_data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                answer = result["choices"][0]["message"]["content"]
                return {
                    "success": True, 
                    "message": f"âœ… è…¾è®¯äº‘DeepSeek APIè¿æ¥æˆåŠŸï¼\nå›å¤: {answer}"
                }
            else:
                error_msg = f"HTTP {response.status_code}"
                try:
                    error_detail = response.json().get('error', {}).get('message', '')
                    error_msg = f"{error_msg}: {error_detail}"
                except:
                    pass
                return {"success": False, "message": f"âŒ APIè¿æ¥å¤±è´¥: {error_msg}"}
                
        except requests.exceptions.RequestException as e:
            return {"success": False, "message": f"âŒ ç½‘ç»œé”™è¯¯: {str(e)}"}
    
    def get_answer(self, question: str, contexts: List[Dict]) -> str:
        """è·å–DeepSeekç­”æ¡ˆ"""
        if not self.is_logged_in():
            return "è¯·å…ˆè®¾ç½®APIå¯†é’¥"
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_text = self._build_context_text(contexts)
        
        prompt = f"""åŸºäºä»¥ä¸‹èµ„æ–™å›ç­”é—®é¢˜ï¼š

ç›¸å…³èµ„æ–™ï¼š
{context_text}

é—®é¢˜ï¼š{question}

è¯·æ ¹æ®èµ„æ–™å†…å®¹ç»™å‡ºå‡†ç¡®ã€ä¸“ä¸šçš„å›ç­”ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·å¦‚å®è¯´æ˜ã€‚"""

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†é—®ç­”åŠ©æ‰‹ï¼Œæ ¹æ®æä¾›çš„èµ„æ–™å‡†ç¡®å›ç­”é—®é¢˜ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,
            "max_tokens": 2000
        }
        
        try:
            response = requests.post(self.base_url, headers=headers, json=data, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            return f"âŒ APIè°ƒç”¨é”™è¯¯ï¼š{str(e)}"
    
    def _build_context_text(self, contexts: List[Dict]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡æ–‡æœ¬"""
        context_text = ""
        for i, context in enumerate(contexts, 1):
            source = context.get('source', 'æœªçŸ¥æ–‡æ¡£')
            page = context.get('page', 'æœªçŸ¥é¡µç ')
            content = context.get('content', '')
            
            doc_name = os.path.basename(source)
            if '.' in doc_name:
                doc_name = doc_name.rsplit('.', 1)[0]
            
            context_text += f"\nã€èµ„æ–™{i}ã€‘ã€Š{doc_name}ã€‹ç¬¬{page}é¡µï¼š\n{content}\n"
        
        return context_text

@st.cache_resource
def init_vector_store():
    """åˆå§‹åŒ–å‘é‡å­˜å‚¨ - åªåŠ è½½ç°æœ‰æ•°æ®åº“"""
    try:
        st.info("ğŸ” æ­£åœ¨åŠ è½½çŸ¥è¯†åº“...")
        
        chroma_db_path = "./chroma_db"
        vector_store = SmartVectorStore()
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(chroma_db_path):
            st.error("âŒ çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨")
            return None
        
        # æ£€æŸ¥ç›®å½•å†…å®¹
        files = os.listdir(chroma_db_path)
        if not files:
            st.error("âŒ çŸ¥è¯†åº“ç›®å½•ä¸ºç©º")
            return None
            
        st.info(f"ğŸ“ æ‰¾åˆ°çŸ¥è¯†åº“ï¼ŒåŒ…å« {len(files)} ä¸ªæ–‡ä»¶")
        
        # ç›´æ¥å°è¯•åŠ è½½
        if vector_store.load_existing_vector_store():
            st.success("âœ… çŸ¥è¯†åº“åŠ è½½æˆåŠŸï¼")
            return vector_store
        else:
            st.error("âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥")
            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯
            try:
                from langchain_community.vectorstores import Chroma
                from langchain_community.embeddings import HuggingFaceEmbeddings
                
                embedding_model = HuggingFaceEmbeddings(
                    model_name="BAAI/bge-small-zh-v1.5",
                    model_kwargs={'device': 'cpu'},
                    encode_kwargs={'normalize_embeddings': True}
                )
                
                test_store = Chroma(
                    persist_directory=chroma_db_path,
                    embedding_function=embedding_model,
                    collection_name="pdf_documents"
                )
                count = test_store._collection.count()
                st.info(f"æµ‹è¯•åŠ è½½æˆåŠŸï¼Œæ–‡æ¡£æ•°é‡: {count}")
            except Exception as e:
                st.error(f"è¯¦ç»†é”™è¯¯: {str(e)}")
            return None
            
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None

def main():
    st.title("ğŸ“ å†°å§é—®ç­”å°è¯¾å ‚")
    st.markdown("---")
    
    # åˆå§‹åŒ–session state
    if 'deepseek_api' not in st.session_state:
        st.session_state.deepseek_api = DeepSeekAPI()
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    deepseek_api = st.session_state.deepseek_api
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ”‘ APIè®¾ç½®")
        
        api_key = st.text_input(
            "è¾“å…¥è…¾è®¯äº‘DeepSeek APIå¯†é’¥:",
            type="password",
            placeholder="sk-...",
            value=st.session_state.get('api_key', '')
        )
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("è®¾ç½®å¯†é’¥"):
                if deepseek_api.set_api_key(api_key):
                    st.rerun()
        with col2:
            if st.button("æµ‹è¯•è¿æ¥"):
                if deepseek_api.is_logged_in():
                    with st.spinner("æµ‹è¯•ä¸­..."):
                        result = deepseek_api.test_api_connection()
                    if result["success"]:
                        st.success(result["message"])
                    else:
                        st.error(result["message"])
                else:
                    st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        
        st.markdown("---")
        st.info("""
        **ä½¿ç”¨è¯´æ˜ï¼š**
        1. è®¾ç½®è…¾è®¯äº‘DeepSeek APIå¯†é’¥
        2. æµ‹è¯•è¿æ¥æ˜¯å¦æˆåŠŸ  
        3. åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜å¼€å§‹é—®ç­”
        """)
        
        # æ˜¾ç¤ºè¿æ¥çŠ¶æ€
        st.markdown("---")
        if st.session_state.api_key_set:
            st.success("âœ… APIå¯†é’¥å·²è®¾ç½®")
        else:
            st.error("âŒ APIå¯†é’¥æœªè®¾ç½®")
    
    # åˆå§‹åŒ–å‘é‡å­˜å‚¨
    vector_store = init_vector_store()
    
    # ä¸»ç•Œé¢å¸ƒå±€
    if vector_store is None:
        st.error("âŒ çŸ¥è¯†åº“æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œé—®ç­”")
        st.info("""
        **è¯·ç¡®ä¿:**
        - `chroma_db` ç›®å½•å·²æ­£ç¡®ä¸Šä¼ 
        - å‘é‡æ•°æ®åº“æ–‡ä»¶å®Œæ•´
        """)
        # ä¸æ˜¾ç¤ºèŠå¤©è¾“å…¥æ¡†
        st.stop()
    
    # çŸ¥è¯†åº“åŠ è½½æˆåŠŸï¼Œæ˜¾ç¤ºä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ’¬ é—®ç­”å¯¹è¯æ¡†")
        st.success("âœ… çŸ¥è¯†åº“å·²åŠ è½½ï¼Œå¯ä»¥å¼€å§‹é—®ç­”")
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ç”¨æˆ·è¾“å…¥ - åªæœ‰åœ¨çŸ¥è¯†åº“åŠ è½½æˆåŠŸæ—¶æ‰æ˜¾ç¤º
        if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
            if not st.session_state.api_key_set:
                st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½®APIå¯†é’¥")
                st.stop()
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # å¤„ç†å›ç­”
            with st.chat_message("assistant"):
                with st.spinner("ğŸ” æœç´¢çŸ¥è¯†åº“..."):
                    try:
                        results = vector_store.search_similar_documents(prompt, k=5)
                        
                        if not results:
                            response = "âŒ æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
                        else:
                            contexts = []
                            for doc in results:
                                contexts.append({
                                    'source': doc.metadata.get('source', 'æœªçŸ¥'),
                                    'page': doc.metadata.get('page', 'æœªçŸ¥'),
                                    'content': doc.page_content
                                })
                            
                            # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡æ¡£ç‰‡æ®µ
                            with st.expander("ğŸ“š æ‰¾åˆ°çš„ç›¸å…³æ–‡æ¡£ç‰‡æ®µ", expanded=False):
                                for i, context in enumerate(contexts, 1):
                                    doc_name = os.path.basename(context['source'])
                                    if '.' in doc_name:
                                        doc_name = doc_name.rsplit('.', 1)[0]
                                    
                                    st.markdown(f"**ç‰‡æ®µ {i}**")
                                    st.markdown(f"**æ–‡æ¡£ï¼š** ã€Š{doc_name}ã€‹")
                                    st.markdown(f"**é¡µç ï¼š** ç¬¬{context['page']}é¡µ")
                                    st.markdown(f"**å†…å®¹ï¼š** {context['content'][:200]}...")
                                    st.markdown("---")
                            
                            # è·å–DeepSeekç­”æ¡ˆ
                            with st.spinner("ğŸ¤” ç”Ÿæˆå›ç­”..."):
                                response = deepseek_api.get_answer(prompt, contexts)
                    
                    except Exception as e:
                        response = f"âŒ æœç´¢çŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}"
                
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
    
    with col2:
        st.subheader("ğŸ“Š çŸ¥è¯†åº“çŠ¶æ€")
        try:
            stats = vector_store.get_document_stats()
            col1, col2 = st.columns(2)
            with col1:
                st.metric("æ€»æ–‡æ¡£æ•°", stats.get('total_documents', 'N/A'))
            with col2:
                st.metric("è·Ÿè¸ªæ–‡ä»¶æ•°", stats.get('tracked_files', 'N/A'))
            
            # æ˜¾ç¤ºæ–‡æ¡£åˆ—è¡¨
            with st.expander("ğŸ“‹ æ–‡æ¡£åˆ—è¡¨"):
                metadata = stats.get('document_metadata', {})
                if metadata:
                    for file_name in list(metadata.keys())[:10]:
                        doc_name = file_name.rsplit('.', 1)[0] if '.' in file_name else file_name
                        st.write(f"â€¢ ã€Š{doc_name}ã€‹")
                else:
                    st.info("æš‚æ— æ–‡æ¡£ä¿¡æ¯")
                    
        except Exception as e:
            st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        st.markdown("---")
        if st.button("æ¸…ç©ºèŠå¤©è®°å½•"):
            st.session_state.messages = []
            st.rerun()

if __name__ == "__main__":
    main()
